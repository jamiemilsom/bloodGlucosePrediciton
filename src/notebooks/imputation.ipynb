{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation\n",
    "As the data has many missing values, we need to look at methods of imputation to maximise the usefulness of the existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.5.1+cu124\n",
      "Cuda available:  True\n",
      "Running on  NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from helper.helper import float_to_time, time_to_float, float_time_range, float_time_minus\n",
    "import random\n",
    "import tqdm\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV,train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# Set seed for repeatability\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed) # np random seed\n",
    "    random.seed(seed) # py random seed\n",
    "seed_everything(seed=1024)\n",
    "import torch\n",
    "print('torch version: ',torch.__version__)\n",
    "print('Cuda available: ',torch.cuda.is_available())\n",
    "print('Running on ',torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema and Useful lists to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['Aerobic Workout', 'Dancing', 'HIIT', 'Indoor climbing', 'Outdoor Bike', 'Run', 'Spinning', 'Sport', 'Swim', 'Walk', 'Weights', 'Workout', 'Yoga']\n",
    "\n",
    "lstm__train_features = [\n",
    "    'id', 'p_num_p01', 'p_num_p02', 'p_num_p03', 'p_num_p04', 'p_num_p05', 'p_num_p06',\n",
    "    'p_num_p10', 'p_num_p11', 'p_num_p12', 'p_num_p15', 'p_num_p16', 'p_num_p18', 'p_num_p19',\n",
    "    'p_num_p21', 'p_num_p22', 'p_num_p24','bg', 'insulin', 'carbs', 'hr', 'steps', \n",
    "    'cals'] + activities\n",
    "\n",
    "lstm_target = ['bg+1:00']\n",
    "\n",
    "lstm_train_schema = {\n",
    "    'id': pl.String,\n",
    "    'time_delta': pl.Float64,\n",
    "    'time': pl.Float64,  \n",
    "    'p_num_p01': pl.Boolean, \n",
    "    'p_num_p02': pl.Boolean,\n",
    "    'p_num_p03': pl.Boolean,\n",
    "    'p_num_p04': pl.Boolean,\n",
    "    'p_num_p05': pl.Boolean,\n",
    "    'p_num_p06': pl.Boolean,\n",
    "    'p_num_p10': pl.Boolean,\n",
    "    'p_num_p11': pl.Boolean,\n",
    "    'p_num_p12': pl.Boolean,\n",
    "    'p_num_p15': pl.Boolean,\n",
    "    'p_num_p16': pl.Boolean,\n",
    "    'p_num_p18': pl.Boolean,\n",
    "    'p_num_p19': pl.Boolean,\n",
    "    'p_num_p21': pl.Boolean,\n",
    "    'p_num_p22': pl.Boolean,\n",
    "    'p_num_p24': pl.Boolean,\n",
    "    'bg': pl.Float64,  \n",
    "    'insulin': pl.Float64,\n",
    "    'carbs': pl.Float64,\n",
    "    'hr': pl.Float64,  \n",
    "    'steps': pl.Float64, \n",
    "    'cals': pl.Float64,\n",
    "}\n",
    "for activity in activities:\n",
    "    lstm_train_schema[activity] = pl.Boolean\n",
    "lstm_train_schema['bg+1:00'] = pl.Float64\n",
    "\n",
    "lstm_test_schema = lstm_train_schema.copy()\n",
    "del lstm_test_schema['bg+1:00']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_participants = ['p_num_p01','p_num_p02','p_num_p03','p_num_p04','p_num_p05','p_num_p06','p_num_p10','p_num_p11','p_num_p12']\n",
    "test_participants = [ 'p_num_p01', 'p_num_p02', 'p_num_p04', 'p_num_p05', 'p_num_p06', 'p_num_p10', 'p_num_p11', 'p_num_p12', 'p_num_p15', 'p_num_p16', 'p_num_p18', 'p_num_p19', 'p_num_p21', 'p_num_p22', 'p_num_p24']\n",
    "all_participants = sorted(set(train_participants + test_participants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features selected for predicting heart rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_pred_feature_cols = ['time','bg','insulin','carbs','hr','steps','cals'] + activities + all_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_df = pl.read_csv('../../data/lstm_sg_train.csv',schema_overrides= lstm_train_schema)\n",
    "lstm_test_df = pl.read_csv('../../data/lstm_sg_test.csv', schema_overrides=lstm_test_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'p_num_p01', 'p_num_p02', 'p_num_p03', 'p_num_p04', 'p_num_p05', 'p_num_p06', 'p_num_p10', 'p_num_p11', 'p_num_p12', 'p_num_p15', 'p_num_p16', 'p_num_p18', 'p_num_p19', 'p_num_p21', 'p_num_p22', 'p_num_p24', 'bg', 'insulin', 'carbs', 'hr', 'steps', 'cals', 'Aerobic Workout', 'Dancing', 'HIIT', 'Indoor climbing', 'Outdoor Bike', 'Run', 'Spinning', 'Sport', 'Swim', 'Walk', 'Weights', 'Workout', 'Yoga']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9673371, 35), (9673371,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hr_pred_df = pl.concat([lstm_train_df.drop(['id','time_delta','bg+1:00']), lstm_test_df.drop(['id','time_delta'])])\n",
    "all_hr_pred_df = all_hr_pred_df.filter(pl.col('hr').is_not_null())\n",
    "print(all_hr_pred_df.columns)\n",
    "\n",
    "t = all_hr_pred_df['hr'].to_numpy().reshape(-1,1)\n",
    "X = all_hr_pred_df.drop('hr').to_numpy()\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "t_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "t = t_scaler.fit_transform(t).ravel()\n",
    "\n",
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([199.3]), array([37.6]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_scaler.data_max_, t_scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_train, label\u001b[38;5;241m=\u001b[39mt_train, missing\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m     25\u001b[0m dval \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_val, label\u001b[38;5;241m=\u001b[39mt_val, missing\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dval)\n\u001b[1;32m     37\u001b[0m score \u001b[38;5;241m=\u001b[39m mean_squared_error(t_val, preds)\n",
      "File \u001b[0;32m~/Documents/bloodGlucosePrediciton/bg_pred/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/bloodGlucosePrediciton/bg_pred/lib/python3.12/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bloodGlucosePrediciton/bg_pred/lib/python3.12/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtrain_full = xgb.DMatrix(X, label=t, missing=np.nan)\n",
    "\n",
    "best_boost_round = 467\n",
    "\n",
    "best_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.7057888338320615,\n",
    "    'min_child_weight': 8,\n",
    "    'reg_lambda': 0.01696500898391533\n",
    "}\n",
    "\n",
    "cv_scores = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    t_train, t_val = t[train_index], t[val_index]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=t_train, missing=np.nan)\n",
    "    dval = xgb.DMatrix(X_val, label=t_val, missing=np.nan)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        num_boost_round=best_boost_round,\n",
    "        evals=[(dval, 'eval')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(dval)\n",
    "    score = mean_squared_error(t_val, preds)\n",
    "    print(f'Fold score: {score}')\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "mean_cv = np.mean(cv_scores)\n",
    "mean_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-27 03:50:49,983] A new study created in memory with name: no-name-30c34ab3-b6b5-4f76-848d-f6f993e510d7\n",
      "[I 2024-11-27 03:53:28,203] Trial 0 finished with value: 0.0039870210187792085 and parameters: {'max_depth': 4, 'learning_rate': 0.534466221123504, 'min_child_weight': 9, 'reg_lambda': 2.7560299352139753e-08, 'num_boost_round': 130}. Best is trial 0 with value: 0.0039870210187792085.\n",
      "[I 2024-11-27 04:01:57,864] Trial 1 finished with value: 0.004107003943048157 and parameters: {'max_depth': 8, 'learning_rate': 0.00652046496450349, 'min_child_weight': 6, 'reg_lambda': 7.779330490591112e-07, 'num_boost_round': 466}. Best is trial 0 with value: 0.0039870210187792085.\n",
      "[I 2024-11-27 04:05:59,179] Trial 2 finished with value: 0.0025609188299128964 and parameters: {'max_depth': 7, 'learning_rate': 0.36065959143027126, 'min_child_weight': 9, 'reg_lambda': 0.1624143688183076, 'num_boost_round': 292}. Best is trial 2 with value: 0.0025609188299128964.\n",
      "[I 2024-11-27 04:10:04,050] Trial 3 finished with value: 0.006890454184293386 and parameters: {'max_depth': 4, 'learning_rate': 0.002520089431414067, 'min_child_weight': 10, 'reg_lambda': 0.010075627947333013, 'num_boost_round': 331}. Best is trial 2 with value: 0.0025609188299128964.\n",
      "[I 2024-11-27 04:12:39,250] Trial 4 finished with value: 0.0039024689566273586 and parameters: {'max_depth': 6, 'learning_rate': 0.10236617433621559, 'min_child_weight': 10, 'reg_lambda': 2.0214171110208735e-05, 'num_boost_round': 188}. Best is trial 2 with value: 0.0025609188299128964.\n",
      "[I 2024-11-27 04:15:01,442] Trial 5 finished with value: 0.008929354827433164 and parameters: {'max_depth': 3, 'learning_rate': 0.0019864538658403274, 'min_child_weight': 1, 'reg_lambda': 0.000758568964185407, 'num_boost_round': 210}. Best is trial 2 with value: 0.0025609188299128964.\n",
      "[I 2024-11-27 04:16:22,357] Trial 6 finished with value: 0.010367080493912034 and parameters: {'max_depth': 8, 'learning_rate': 0.002813204929640592, 'min_child_weight': 6, 'reg_lambda': 9.983149822934316e-06, 'num_boost_round': 53}. Best is trial 2 with value: 0.0025609188299128964.\n",
      "[I 2024-11-27 04:22:49,732] Trial 7 finished with value: 0.001130104232524033 and parameters: {'max_depth': 8, 'learning_rate': 0.7033956589116328, 'min_child_weight': 5, 'reg_lambda': 0.381799520051769, 'num_boost_round': 435}. Best is trial 7 with value: 0.001130104232524033.\n",
      "[I 2024-11-27 04:26:36,885] Trial 8 finished with value: 0.004361979144511722 and parameters: {'max_depth': 3, 'learning_rate': 0.09649620722934815, 'min_child_weight': 7, 'reg_lambda': 0.0016202791936165955, 'num_boost_round': 445}. Best is trial 7 with value: 0.001130104232524033.\n",
      "[I 2024-11-27 04:28:54,709] Trial 9 finished with value: 0.004225687021232267 and parameters: {'max_depth': 5, 'learning_rate': 0.07723651203202175, 'min_child_weight': 1, 'reg_lambda': 0.00063020181982945, 'num_boost_round': 188}. Best is trial 7 with value: 0.001130104232524033.\n",
      "[I 2024-11-27 04:35:58,790] Trial 10 finished with value: 0.0004422791702677293 and parameters: {'max_depth': 10, 'learning_rate': 0.9564649953407274, 'min_child_weight': 3, 'reg_lambda': 0.3101907912749598, 'num_boost_round': 380}. Best is trial 10 with value: 0.0004422791702677293.\n",
      "[I 2024-11-27 04:43:05,509] Trial 11 finished with value: 0.00043556616442673777 and parameters: {'max_depth': 10, 'learning_rate': 0.9227730846134722, 'min_child_weight': 3, 'reg_lambda': 0.6085078655855296, 'num_boost_round': 383}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 04:49:56,969] Trial 12 finished with value: 0.0004431160024788174 and parameters: {'max_depth': 10, 'learning_rate': 0.9334100029908519, 'min_child_weight': 3, 'reg_lambda': 0.9490008395848074, 'num_boost_round': 369}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 04:57:10,562] Trial 13 finished with value: 0.0033106851996697758 and parameters: {'max_depth': 10, 'learning_rate': 0.017634723789947064, 'min_child_weight': 3, 'reg_lambda': 0.028331052746353613, 'num_boost_round': 357}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:04:15,197] Trial 14 finished with value: 0.0010576135026934704 and parameters: {'max_depth': 10, 'learning_rate': 0.23775653400955862, 'min_child_weight': 3, 'reg_lambda': 0.021493217632892903, 'num_boost_round': 409}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:08:58,773] Trial 15 finished with value: 0.0020272739184595983 and parameters: {'max_depth': 9, 'learning_rate': 0.2055628301958387, 'min_child_weight': 4, 'reg_lambda': 0.0819827509845316, 'num_boost_round': 292}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:17:01,251] Trial 16 finished with value: 0.0032843640297847048 and parameters: {'max_depth': 9, 'learning_rate': 0.02816965071313807, 'min_child_weight': 2, 'reg_lambda': 0.0047066778735785, 'num_boost_round': 500}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:23:34,967] Trial 17 finished with value: 0.0006697939746128289 and parameters: {'max_depth': 9, 'learning_rate': 0.9460925477119052, 'min_child_weight': 4, 'reg_lambda': 0.9566262045065047, 'num_boost_round': 390}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:26:57,543] Trial 18 finished with value: 0.0031421687029280325 and parameters: {'max_depth': 7, 'learning_rate': 0.1966738218580271, 'min_child_weight': 2, 'reg_lambda': 0.00014802533844693634, 'num_boost_round': 244}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:33:08,838] Trial 19 finished with value: 0.002838450881648912 and parameters: {'max_depth': 10, 'learning_rate': 0.048404939186684454, 'min_child_weight': 5, 'reg_lambda': 0.0784629138743006, 'num_boost_round': 335}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:40:43,381] Trial 20 finished with value: 0.003554951096788329 and parameters: {'max_depth': 9, 'learning_rate': 0.016433004374253234, 'min_child_weight': 7, 'reg_lambda': 1.5323303668711844e-08, 'num_boost_round': 410}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:47:16,746] Trial 21 finished with value: 0.0007135205350950429 and parameters: {'max_depth': 10, 'learning_rate': 0.4215013066306386, 'min_child_weight': 3, 'reg_lambda': 0.9654574829324036, 'num_boost_round': 358}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:54:31,126] Trial 22 finished with value: 0.00044511482613986277 and parameters: {'max_depth': 10, 'learning_rate': 0.9282783358143609, 'min_child_weight': 4, 'reg_lambda': 0.1931112713680741, 'num_boost_round': 378}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 05:59:52,822] Trial 23 finished with value: 0.0013474354477206844 and parameters: {'max_depth': 9, 'learning_rate': 0.37595567145109937, 'min_child_weight': 2, 'reg_lambda': 0.9020175146776491, 'num_boost_round': 317}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:04:10,887] Trial 24 finished with value: 0.0014724496960034103 and parameters: {'max_depth': 8, 'learning_rate': 0.9998645114683562, 'min_child_weight': 3, 'reg_lambda': 0.04742535802423704, 'num_boost_round': 263}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:12:33,174] Trial 25 finished with value: 0.001216799556433804 and parameters: {'max_depth': 10, 'learning_rate': 0.17613273004820046, 'min_child_weight': 1, 'reg_lambda': 0.0037103546311763906, 'num_boost_round': 477}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:19:29,861] Trial 26 finished with value: 0.0008473506970608314 and parameters: {'max_depth': 9, 'learning_rate': 0.521955010563327, 'min_child_weight': 4, 'reg_lambda': 0.21435499296769908, 'num_boost_round': 416}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:24:42,160] Trial 27 finished with value: 0.002392317881370824 and parameters: {'max_depth': 7, 'learning_rate': 0.33959609777069816, 'min_child_weight': 2, 'reg_lambda': 0.017805723261624152, 'num_boost_round': 375}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:28:44,112] Trial 28 finished with value: 0.002731866461600399 and parameters: {'max_depth': 6, 'learning_rate': 0.6154733359821155, 'min_child_weight': 3, 'reg_lambda': 0.3174582630140576, 'num_boost_round': 313}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:31:14,116] Trial 29 finished with value: 0.002810902688808879 and parameters: {'max_depth': 10, 'learning_rate': 0.1359439712310454, 'min_child_weight': 5, 'reg_lambda': 2.7782509664039756e-07, 'num_boost_round': 118}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:36:33,783] Trial 30 finished with value: 0.001418477606907981 and parameters: {'max_depth': 8, 'learning_rate': 0.6079003770758594, 'min_child_weight': 7, 'reg_lambda': 0.00010852296127860838, 'num_boost_round': 346}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:43:58,310] Trial 31 finished with value: 0.00044050441285944697 and parameters: {'max_depth': 10, 'learning_rate': 0.9920926947003181, 'min_child_weight': 4, 'reg_lambda': 0.18346529903982506, 'num_boost_round': 392}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:52:03,151] Trial 32 finished with value: 0.0007496121165721009 and parameters: {'max_depth': 10, 'learning_rate': 0.31344446604045245, 'min_child_weight': 4, 'reg_lambda': 0.10627304481705485, 'num_boost_round': 450}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 06:58:41,979] Trial 33 finished with value: 0.0007909130314449937 and parameters: {'max_depth': 9, 'learning_rate': 0.6124934499302176, 'min_child_weight': 2, 'reg_lambda': 0.4906686275435329, 'num_boost_round': 396}. Best is trial 11 with value: 0.00043556616442673777.\n",
      "[I 2024-11-27 07:06:51,765] Trial 34 finished with value: 0.0004230719614047696 and parameters: {'max_depth': 10, 'learning_rate': 0.9794981679206517, 'min_child_weight': 6, 'reg_lambda': 0.009006649835017894, 'num_boost_round': 431}. Best is trial 34 with value: 0.0004230719614047696.\n",
      "[I 2024-11-27 07:14:39,230] Trial 35 finished with value: 0.0011416400117866953 and parameters: {'max_depth': 9, 'learning_rate': 0.2973495330036869, 'min_child_weight': 6, 'reg_lambda': 0.004840329160953434, 'num_boost_round': 488}. Best is trial 34 with value: 0.0004230719614047696.\n",
      "[I 2024-11-27 07:21:30,446] Trial 36 finished with value: 0.0013332699198500878 and parameters: {'max_depth': 8, 'learning_rate': 0.4758951253044236, 'min_child_weight': 8, 'reg_lambda': 0.051391819915268346, 'num_boost_round': 459}. Best is trial 34 with value: 0.0004230719614047696.\n",
      "[I 2024-11-27 07:27:18,207] Trial 37 finished with value: 0.008352581787313183 and parameters: {'max_depth': 5, 'learning_rate': 0.001004429032825598, 'min_child_weight': 5, 'reg_lambda': 1.4014571361260108e-05, 'num_boost_round': 427}. Best is trial 34 with value: 0.0004230719614047696.\n",
      "[I 2024-11-27 07:35:51,794] Trial 38 finished with value: 0.0004114389510458025 and parameters: {'max_depth': 10, 'learning_rate': 0.7057888338320615, 'min_child_weight': 8, 'reg_lambda': 0.01696500898391533, 'num_boost_round': 467}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 07:45:27,752] Trial 39 finished with value: 0.0038976433210522535 and parameters: {'max_depth': 9, 'learning_rate': 0.006306877449577494, 'min_child_weight': 9, 'reg_lambda': 0.009754854373079965, 'num_boost_round': 475}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 07:52:05,690] Trial 40 finished with value: 0.0011497830159861845 and parameters: {'max_depth': 8, 'learning_rate': 0.6700321955445028, 'min_child_weight': 8, 'reg_lambda': 0.0004924797800272553, 'num_boost_round': 435}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 07:59:23,771] Trial 41 finished with value: 0.00045758056875343277 and parameters: {'max_depth': 10, 'learning_rate': 0.7300650459213284, 'min_child_weight': 9, 'reg_lambda': 0.1454730178023734, 'num_boost_round': 393}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:07:39,384] Trial 42 finished with value: 0.000549656927062932 and parameters: {'max_depth': 10, 'learning_rate': 0.44483875740920126, 'min_child_weight': 10, 'reg_lambda': 0.012108073993014393, 'num_boost_round': 461}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:15:36,741] Trial 43 finished with value: 0.00042954812643796234 and parameters: {'max_depth': 10, 'learning_rate': 0.7412492720807624, 'min_child_weight': 8, 'reg_lambda': 0.002137108427483128, 'num_boost_round': 431}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:22:45,021] Trial 44 finished with value: 0.0013326861828122497 and parameters: {'max_depth': 9, 'learning_rate': 0.26568283160990647, 'min_child_weight': 8, 'reg_lambda': 0.0011450833017390954, 'num_boost_round': 442}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:30:36,797] Trial 45 finished with value: 0.0004289428235125423 and parameters: {'max_depth': 10, 'learning_rate': 0.7408078913286973, 'min_child_weight': 7, 'reg_lambda': 0.002722832345701187, 'num_boost_round': 423}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:34:50,230] Trial 46 finished with value: 0.004028903617173712 and parameters: {'max_depth': 4, 'learning_rate': 0.12877135968566497, 'min_child_weight': 6, 'reg_lambda': 4.3385555820465336e-05, 'num_boost_round': 422}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:43:19,245] Trial 47 finished with value: 0.00234107459006423 and parameters: {'max_depth': 10, 'learning_rate': 0.06026478455724148, 'min_child_weight': 7, 'reg_lambda': 0.002262901393113174, 'num_boost_round': 487}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:50:41,755] Trial 48 finished with value: 0.0009527438552934779 and parameters: {'max_depth': 9, 'learning_rate': 0.40622908774437, 'min_child_weight': 9, 'reg_lambda': 0.0002129159226599478, 'num_boost_round': 452}. Best is trial 38 with value: 0.0004114389510458025.\n",
      "[I 2024-11-27 08:58:15,508] Trial 49 finished with value: 0.0004421848896434486 and parameters: {'max_depth': 10, 'learning_rate': 0.7377443121667324, 'min_child_weight': 7, 'reg_lambda': 0.0003168674574129288, 'num_boost_round': 407}. Best is trial 38 with value: 0.0004114389510458025.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.0004114389510458025\n",
      "  Params: \n",
      "    max_depth: 10\n",
      "    learning_rate: 0.7057888338320615\n",
      "    min_child_weight: 8\n",
      "    reg_lambda: 0.01696500898391533\n",
      "    num_boost_round: 467\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True)  \n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 50, 500)\n",
    "\n",
    "    cv_scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        t_train, t_val = t[train_index], t[val_index]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=t_train, missing=np.nan)\n",
    "        dval = xgb.DMatrix(X_val, label=t_val, missing=np.nan)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dval, 'eval')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        preds = model.predict(dval)\n",
    "        score = mean_squared_error(t_val, preds)\n",
    "        cv_scores.append(score)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(n_trials=20):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "best_params = optimize_hyperparameters(n_trials=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputating the bg rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_hr_train_df = pl.read_csv('../../data/lstm_hr_train.csv',schema_overrides= lstm_train_schema)\n",
    "lstm_hr_test_df = pl.read_csv('../../data/lstm_hr_test.csv', schema_overrides=lstm_test_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12848343, 35), (12848343, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bg_pred_df = pl.concat([lstm_hr_train_df.drop(['id','time_delta','bg+1:00']), lstm_hr_test_df.drop(['id','time_delta'])])\n",
    "all_bg_pred_df = all_bg_pred_df.filter(pl.col('bg').is_not_null())\n",
    "\n",
    "t = all_bg_pred_df['bg'].to_numpy().reshape(-1,1)\n",
    "X = all_bg_pred_df.drop('bg').to_numpy()\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "t_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "t = t_scaler.fit_transform(t)\n",
    "\n",
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'p_num_p01',\n",
       " 'p_num_p02',\n",
       " 'p_num_p03',\n",
       " 'p_num_p04',\n",
       " 'p_num_p05',\n",
       " 'p_num_p06',\n",
       " 'p_num_p10',\n",
       " 'p_num_p11',\n",
       " 'p_num_p12',\n",
       " 'p_num_p15',\n",
       " 'p_num_p16',\n",
       " 'p_num_p18',\n",
       " 'p_num_p19',\n",
       " 'p_num_p21',\n",
       " 'p_num_p22',\n",
       " 'p_num_p24',\n",
       " 'bg',\n",
       " 'insulin',\n",
       " 'carbs',\n",
       " 'hr',\n",
       " 'steps',\n",
       " 'cals',\n",
       " 'Aerobic Workout',\n",
       " 'Dancing',\n",
       " 'HIIT',\n",
       " 'Indoor climbing',\n",
       " 'Outdoor Bike',\n",
       " 'Run',\n",
       " 'Spinning',\n",
       " 'Sport',\n",
       " 'Swim',\n",
       " 'Walk',\n",
       " 'Weights',\n",
       " 'Workout',\n",
       " 'Yoga']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bg_pred_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27.8]), array([2.2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_scaler.data_max_, t_scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-27 11:12:25,999] A new study created in memory with name: no-name-08104fb7-8c00-4e54-a446-7942fc5b97b1\n",
      "[I 2024-11-27 11:14:44,338] Trial 0 finished with value: 0.006891279743088864 and parameters: {'max_depth': 8, 'learning_rate': 0.3043410100585595, 'min_child_weight': 2, 'reg_lambda': 1.0246609805689392e-07, 'num_boost_round': 76}. Best is trial 0 with value: 0.006891279743088864.\n",
      "[I 2024-11-27 11:17:19,851] Trial 1 finished with value: 0.007333521855663806 and parameters: {'max_depth': 5, 'learning_rate': 0.8695852939610327, 'min_child_weight': 4, 'reg_lambda': 3.917752038200939e-05, 'num_boost_round': 153}. Best is trial 0 with value: 0.006891279743088864.\n",
      "[I 2024-11-27 11:21:17,513] Trial 2 finished with value: 0.009861646730914718 and parameters: {'max_depth': 9, 'learning_rate': 0.0047074619929575795, 'min_child_weight': 4, 'reg_lambda': 8.941119954360705e-07, 'num_boost_round': 150}. Best is trial 0 with value: 0.006891279743088864.\n",
      "[I 2024-11-27 11:22:59,160] Trial 3 finished with value: 0.01006818679607371 and parameters: {'max_depth': 3, 'learning_rate': 0.033269170396496475, 'min_child_weight': 6, 'reg_lambda': 0.005343612465334583, 'num_boost_round': 80}. Best is trial 0 with value: 0.006891279743088864.\n",
      "[I 2024-11-27 11:26:37,432] Trial 4 finished with value: 0.012125123640423795 and parameters: {'max_depth': 3, 'learning_rate': 0.001569740573729786, 'min_child_weight': 5, 'reg_lambda': 0.0010589227433191121, 'num_boost_round': 275}. Best is trial 0 with value: 0.006891279743088864.\n",
      "[I 2024-11-27 11:30:08,073] Trial 5 finished with value: 0.006667578650619547 and parameters: {'max_depth': 8, 'learning_rate': 0.16092399410393135, 'min_child_weight': 9, 'reg_lambda': 0.39237157600579564, 'num_boost_round': 184}. Best is trial 5 with value: 0.006667578650619547.\n",
      "[I 2024-11-27 11:32:10,993] Trial 6 finished with value: 0.012958369388020636 and parameters: {'max_depth': 5, 'learning_rate': 0.001305409636685653, 'min_child_weight': 4, 'reg_lambda': 1.2491844665806103e-05, 'num_boost_round': 90}. Best is trial 5 with value: 0.006667578650619547.\n",
      "[I 2024-11-27 11:38:04,795] Trial 7 finished with value: 0.011690515414150034 and parameters: {'max_depth': 8, 'learning_rate': 0.00105140632942243, 'min_child_weight': 5, 'reg_lambda': 0.007576004014640648, 'num_boost_round': 275}. Best is trial 5 with value: 0.006667578650619547.\n",
      "[I 2024-11-27 11:40:47,756] Trial 8 finished with value: 0.010322715533569723 and parameters: {'max_depth': 3, 'learning_rate': 0.010779799509370675, 'min_child_weight': 9, 'reg_lambda': 0.023111260009193578, 'num_boost_round': 192}. Best is trial 5 with value: 0.006667578650619547.\n",
      "[I 2024-11-27 11:44:43,807] Trial 9 finished with value: 0.007370580278773904 and parameters: {'max_depth': 6, 'learning_rate': 0.16544021684562973, 'min_child_weight': 3, 'reg_lambda': 0.0010557212888261745, 'num_boost_round': 260}. Best is trial 5 with value: 0.006667578650619547.\n",
      "[I 2024-11-27 11:52:59,743] Trial 10 finished with value: 0.005666347214965779 and parameters: {'max_depth': 10, 'learning_rate': 0.058197765472386385, 'min_child_weight': 10, 'reg_lambda': 0.396211524613941, 'num_boost_round': 442}. Best is trial 10 with value: 0.005666347214965779.\n",
      "[I 2024-11-27 12:01:43,734] Trial 11 finished with value: 0.005521310611477374 and parameters: {'max_depth': 10, 'learning_rate': 0.06203152828267604, 'min_child_weight': 10, 'reg_lambda': 0.9955717342112775, 'num_boost_round': 461}. Best is trial 11 with value: 0.005521310611477374.\n",
      "[I 2024-11-27 12:11:05,828] Trial 12 finished with value: 0.006087443806829325 and parameters: {'max_depth': 10, 'learning_rate': 0.04139507179449447, 'min_child_weight': 10, 'reg_lambda': 0.6435053267513682, 'num_boost_round': 480}. Best is trial 11 with value: 0.005521310611477374.\n",
      "[I 2024-11-27 12:20:06,508] Trial 13 finished with value: 0.005276509363309939 and parameters: {'max_depth': 10, 'learning_rate': 0.06838072731267114, 'min_child_weight': 8, 'reg_lambda': 0.13896970549137339, 'num_boost_round': 484}. Best is trial 13 with value: 0.005276509363309939.\n",
      "[I 2024-11-27 12:29:17,072] Trial 14 finished with value: 0.007297864026224898 and parameters: {'max_depth': 10, 'learning_rate': 0.010374180514155491, 'min_child_weight': 7, 'reg_lambda': 0.05740743930851763, 'num_boost_round': 379}. Best is trial 13 with value: 0.005276509363309939.\n",
      "[I 2024-11-27 12:36:07,120] Trial 15 finished with value: 0.005849084747161641 and parameters: {'max_depth': 9, 'learning_rate': 0.0917404924942552, 'min_child_weight': 8, 'reg_lambda': 0.08053063917422412, 'num_boost_round': 390}. Best is trial 13 with value: 0.005276509363309939.\n",
      "[I 2024-11-27 12:42:23,883] Trial 16 finished with value: 0.008214327593773487 and parameters: {'max_depth': 7, 'learning_rate': 0.015033287896788098, 'min_child_weight': 8, 'reg_lambda': 0.0005846019344786901, 'num_boost_round': 362}. Best is trial 13 with value: 0.005276509363309939.\n",
      "[I 2024-11-27 12:50:46,080] Trial 17 finished with value: 0.002949414413289265 and parameters: {'max_depth': 9, 'learning_rate': 0.363255561231773, 'min_child_weight': 7, 'reg_lambda': 0.9168778809161837, 'num_boost_round': 483}. Best is trial 17 with value: 0.002949414413289265.\n",
      "[I 2024-11-27 12:58:36,393] Trial 18 finished with value: 0.0020402501658796112 and parameters: {'max_depth': 9, 'learning_rate': 0.9654913454263729, 'min_child_weight': 7, 'reg_lambda': 0.06472962504852985, 'num_boost_round': 423}. Best is trial 18 with value: 0.0020402501658796112.\n",
      "[I 2024-11-27 13:05:02,519] Trial 19 finished with value: 0.004553202426844922 and parameters: {'max_depth': 7, 'learning_rate': 0.698894097708476, 'min_child_weight': 6, 'reg_lambda': 3.000117155358241e-06, 'num_boost_round': 422}. Best is trial 18 with value: 0.0020402501658796112.\n",
      "[I 2024-11-27 13:11:13,235] Trial 20 finished with value: 0.0033117435020973028 and parameters: {'max_depth': 9, 'learning_rate': 0.4272605193156276, 'min_child_weight': 7, 'reg_lambda': 0.0001457086106863733, 'num_boost_round': 339}. Best is trial 18 with value: 0.0020402501658796112.\n",
      "[I 2024-11-27 13:17:19,147] Trial 21 finished with value: 0.003409075229222533 and parameters: {'max_depth': 9, 'learning_rate': 0.4181330298465312, 'min_child_weight': 7, 'reg_lambda': 0.00013619320753513743, 'num_boost_round': 329}. Best is trial 18 with value: 0.0020402501658796112.\n",
      "[I 2024-11-27 13:23:12,716] Trial 22 finished with value: 0.0034404802069983266 and parameters: {'max_depth': 9, 'learning_rate': 0.4086597776691454, 'min_child_weight': 7, 'reg_lambda': 1.2098036068288647e-08, 'num_boost_round': 331}. Best is trial 18 with value: 0.0020402501658796112.\n",
      "[I 2024-11-27 13:30:21,720] Trial 23 finished with value: 0.0031564562357800988 and parameters: {'max_depth': 8, 'learning_rate': 0.965378952936601, 'min_child_weight': 6, 'reg_lambda': 0.013092091111945856, 'num_boost_round': 414}. Best is trial 18 with value: 0.0020402501658796112.\n",
      "[I 2024-11-27 13:38:53,877] Trial 24 finished with value: 0.0028402807086548693 and parameters: {'max_depth': 8, 'learning_rate': 0.9642974003787687, 'min_child_weight': 1, 'reg_lambda': 0.010803192811236264, 'num_boost_round': 500}. Best is trial 18 with value: 0.0020402501658796112.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.0020402501658796112\n",
      "  Params: \n",
      "    max_depth: 9\n",
      "    learning_rate: 0.9654913454263729\n",
      "    min_child_weight: 7\n",
      "    reg_lambda: 0.06472962504852985\n",
      "    num_boost_round: 423\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True)  \n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 50, 500)\n",
    "\n",
    "    cv_scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        t_train, t_val = t[train_index], t[val_index]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=t_train, missing=np.nan)\n",
    "        dval = xgb.DMatrix(X_val, label=t_val, missing=np.nan)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dval, 'eval')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        preds = model.predict(dval)\n",
    "        score = mean_squared_error(t_val, preds)\n",
    "        cv_scores.append(score)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(n_trials=20):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "best_params = optimize_hyperparameters(n_trials=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_df = pl.read_csv('../../data/lstm_train.csv', schema_overrides=lstm_train_schema)\n",
    "lstm_test_df = pl.read_csv('../../data/lstm_test.csv', schema_overrides=lstm_test_schema)\n",
    "lstm_hr_train_df = pl.read_csv('../../data/lstm_hr_train.csv', schema_overrides=lstm_train_schema)\n",
    "lstm_hr_test_df = pl.read_csv('../../data/lstm_hr_test.csv', schema_overrides=lstm_test_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into some small sections to assess different imputation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_train_pred_df = lstm_train_df.group_by('id').agg(\n",
    "    pl.col('time'),\n",
    "    pl.col('hr')\n",
    ")\n",
    "\n",
    "bg_train_pred_df = bg_train_pred_df.filter(\n",
    "    pl.col('hr').list.eval(pl.element().is_not_null()).list[0]\n",
    ")\n",
    "bg_train_pred_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = 'p05_550'\n",
    "train_section = lstm_train_df.filter(pl.col('id') == ids).fill_null(0)\n",
    "hr_section = lstm_hr_train_df.filter(pl.col('id') == ids).fill_null(0)\n",
    "knn_section = imputed_clean_hr_df.filter(pl.col('id') == ids).fill_null(0)\n",
    "train_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "ax1 = sns.lineplot(data=train_section.to_pandas(), x='time', y='hr', marker='.', label='hr',color='red')\n",
    "ax2 = plt.gca().twinx()  \n",
    "sns.scatterplot(data=train_section.to_pandas(), x='time', y='bg', marker='.', label='bg', ax=ax2, color='green')\n",
    "sns.scatterplot(data=train_section.to_pandas(), x='time', y='insulin', marker='.', label='insulin', ax=ax2, color='blue')\n",
    "sns.scatterplot(data=train_section.to_pandas(), x='time', y='carbs', marker='.', label='carbs', ax=ax2, color='orange')\n",
    "sns.scatterplot(data=train_section.to_pandas(), x='time', y='steps', marker='.', label='steps', ax=ax2, color='purple')\n",
    "sns.scatterplot(data=train_section.to_pandas(), x='time', y='cals', marker='.', label='cals', ax=ax2, color='pink')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "ax3 = sns.lineplot(data=hr_section.to_pandas(), x='time', y='hr', marker='.', label='hr', color='red')\n",
    "ax4 = plt.gca().twinx()  \n",
    "sns.scatterplot(data=hr_section.to_pandas(), x='time', y='bg', marker='.', label='bg', ax=ax4, color='green')\n",
    "sns.scatterplot(data=hr_section.to_pandas(), x='time', y='insulin', marker='.', label='insulin', ax=ax4, color='blue')\n",
    "sns.scatterplot(data=hr_section.to_pandas(), x='time', y='carbs', marker='.', label='carbs', ax=ax4, color='orange')\n",
    "sns.scatterplot(data=hr_section.to_pandas(), x='time', y='steps', marker='.', label='steps', ax=ax4, color='purple')\n",
    "sns.scatterplot(data=hr_section.to_pandas(), x='time', y='cals', marker='.', label='cals', ax=ax4, color='pink')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "ax5 = sns.lineplot(data=train_section.to_pandas(), x='time', y='hr', marker='.', label='hr', color='red')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = { # obtained from hyperparameter tuning on google colab\n",
    "    'subsample': 1.0,\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.2,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "final_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "clean_train_hr_df = lstm_train_df.filter(pl.col('hr').is_not_null()).select(hr_pred_feature_cols + ['hr'])\n",
    "clean_test_hr_df = lstm_test_df.filter(pl.col('hr').is_not_null()).select(hr_pred_feature_cols + ['hr'])\n",
    "\n",
    "clean_hr_df = pl.concat([clean_train_hr_df, clean_test_hr_df])\n",
    "\n",
    "X = clean_hr_df.select(hr_pred_feature_cols)\n",
    "y = clean_hr_df.select('hr')\n",
    "X_np = X.to_numpy()\n",
    "y_np = y.to_numpy().ravel()\n",
    "\n",
    "final_model.fit(X_np, y_np)\n",
    "\n",
    "def imputate_hr_values(df, model, output_path):\n",
    "\n",
    "    missing_hr_df = df.filter(pl.col('hr').is_null())\n",
    "\n",
    "    X_missing = missing_hr_df.select(hr_pred_feature_cols)\n",
    "    X_missing_np = X_missing.to_numpy()\n",
    "\n",
    "    predicted_hr = final_model.predict(X_missing_np)\n",
    "    predicted_hr_lst = [hr for hr in predicted_hr]\n",
    "\n",
    "    pd_df = df.to_pandas()\n",
    "\n",
    "    predicted_hr_lst_copy = pd.Series(predicted_hr_lst)\n",
    "\n",
    "    missing_mask = pd_df['hr'].isnull() \n",
    "    missing_count = missing_mask.sum()\n",
    "    print(f\"Number of missing 'hr' values: {missing_count}\")\n",
    "\n",
    "    if missing_count > 0:\n",
    "        pd_df.loc[missing_mask, 'hr'] = predicted_hr_lst_copy[:missing_count].values\n",
    "\n",
    "    pd_df.to_csv(output_path, index=False)\n",
    "\n",
    "# imputate_hr_values(lstm_train_df, final_model, '../../data/lstm_hr_train.csv')\n",
    "# imputate_hr_values(lstm_test_df, final_model, '../../data/lstm_hr_test.csv')\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = final_model.feature_importances_\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(hr_pred_feature_cols, importances, color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance from XGBoost')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to use the Iterative Imputer from scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train columns not in test'\n",
    ")\n",
    "for col in lstm_train_df.columns:\n",
    "    if col not in lstm_test_df.columns:\n",
    "        print(col)\n",
    "\n",
    "print('Test columns not in train')\n",
    "for col in lstm_test_df.columns:\n",
    "    if col not in lstm_train_df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn_data = pl.concat([lstm_train_df.drop(['bg+1:00','id']), lstm_test_df.drop('id')]).to_numpy()\n",
    "\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "\n",
    "knn_cleaned = knn_imputer.fit_transform(knn_data)\n",
    "\n",
    "imputed_clean_hr_df = pl.DataFrame(knn_cleaned, schema = lstm_test_schema)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bg_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
